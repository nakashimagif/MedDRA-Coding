{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "%matplotlib inline\n",
    "#import sympy\n",
    "import scipy\n",
    "# init_session()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import itertools\n",
    "from itertools import chain, permutations\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of number of words per AETERM\n",
      "data\n",
      " 1      573\n",
      "2     1869\n",
      "3     1558\n",
      "4      893\n",
      "5      259\n",
      "6       62\n",
      "7       20\n",
      "8        9\n",
      "9        2\n",
      "15       1\n",
      "Name: len, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import read_data\n",
    "df = read_data.read_data()\n",
    "\n",
    "\n",
    "def is_ascii(string):\n",
    "    \"\"\"return true if non ascii characters are detected in the given string\n",
    "    \"\"\"\n",
    "    if string:\n",
    "        return max([ord(char) for char in string]) < 128\n",
    "    return True\n",
    "\n",
    "\n",
    "def texts2list(texts):\n",
    "    stop_words = set('for a of the and to in by with'.split())\n",
    "    if type(texts) == list:\n",
    "        texts = pd.Series(texts)\n",
    "    texts = texts.str.lower().str.translate(str.maketrans('()', '  '))\n",
    "    texts = texts.str.strip()\n",
    "    textlist = [[\n",
    "        word for word in document.translate(\n",
    "            str.maketrans('\\'()[],.&?\"{}-_:;', '                ')).split()\n",
    "        if word not in stop_words\n",
    "    ] for document in texts]\n",
    "    return textlist\n",
    "\n",
    "\n",
    "#Select AE reported in English\n",
    "df = df[df['AEDECOD'].apply(is_ascii)]\n",
    "df['AETERM'] = df['AETERM'].str.lower()\n",
    "#drop duplicate\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#create coder and decoder\n",
    "pt = df['AEDECOD'].drop_duplicates()\n",
    "coder = {}\n",
    "for i, word in enumerate(pt):\n",
    "    coder.update({word: i})\n",
    "    i = i + 1\n",
    "decoder = dict([(pt, index) for index, pt in coder.items()])\n",
    "dest = os.path.join('.', 'data', 'coder.pkl')\n",
    "pickle.dump(coder, open(dest, 'wb'), protocol=4)\n",
    "\n",
    "\n",
    "def count_aeterm(df):\n",
    "    texts = texts2list(df['AETERM'])\n",
    "    check = [len(text) for text in texts]\n",
    "    df['len'] = check\n",
    "    print('distribution of number of words per AETERM')\n",
    "    print('data\\n', df['len'].value_counts().sort_index())\n",
    "\n",
    "\n",
    "count_aeterm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.engine import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, LSTM, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wikimodel = Word2Vec.load(\"./data/wiki.en.word2vec.model\")\n",
    "wvsize = wikimodel.vector_size\n",
    "MAX_WORDS = 5\n",
    "\n",
    "texts = texts2list(df['AETERM'])\n",
    "dictset = list(set(chain.from_iterable(texts)))\n",
    "wvdict = dict(\n",
    "    [(dic, wikimodel[dic]) for dic in dictset if dic in wikimodel.wv.vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texts2wv(texts):\n",
    "    wv = [\n",
    "        np.array([wvdict[word] for word in text if word in wvdict.keys()])\n",
    "        for text in texts\n",
    "    ]\n",
    "    nonull = [len(vector) for vector in wv]\n",
    "    x = [\n",
    "        np.array([\n",
    "            wvdict[word] for (i, word) in enumerate(text)\n",
    "            if word in wvdict.keys()\n",
    "        ]) for text in texts\n",
    "    ]\n",
    "    x_norm = [x[i][0:MAX_WORDS] for i in range(len(x))]\n",
    "    x_all = np.array([\n",
    "        np.append(x_norm[i].flat,\n",
    "                  np.zeros(wvsize * max(MAX_WORDS - len(x_norm[i]), 0)))\n",
    "        for i in range(len(x_norm))\n",
    "    ])\n",
    "    return x_all, nonull\n",
    "\n",
    "\n",
    "texts = texts2list(df['AETERM'])\n",
    "x_all, nonnull = texts2wv(texts)\n",
    "df['nonnull'] = nonnull\n",
    "df = df[df.nonnull > 0]\n",
    "df_all = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique PT(#>=1):  1553\n",
      "Unique PT(#>=2):  721\n",
      "All Record\n",
      "distribution of number of words per AETERM\n",
      "data\n",
      " 1      429\n",
      "2     1858\n",
      "3     1557\n",
      "4      893\n",
      "5      259\n",
      "6       62\n",
      "7       20\n",
      "8        9\n",
      "9        2\n",
      "15       1\n",
      "Name: len, dtype: int64\n",
      "#AEDECOD>=2\n",
      "distribution of number of words per AETERM\n",
      "data\n",
      " 1      297\n",
      "2     1503\n",
      "3     1336\n",
      "4      815\n",
      "5      227\n",
      "6       54\n",
      "7       15\n",
      "8        8\n",
      "9        2\n",
      "15       1\n",
      "Name: len, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sizeflag = df_all.groupby(\"AEDECOD\").size().reset_index()\n",
    "sizeflag.columns = ['AEDECOD', 'AEDECOD_SIZE']\n",
    "df = pd.merge(df_all, sizeflag, on=\"AEDECOD\", how=\"left\")\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select AEDECOD which have 2 or more record\n",
    "df = df[df['AEDECOD_SIZE'] >= 2]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Unique PT(#>=1): \", len(df_all[~df_all['AEDECOD'].duplicated()]))\n",
    "print(\"Unique PT(#>=2): \", len(df[~df['AEDECOD'].duplicated()]))\n",
    "\n",
    "\n",
    "def sampling(groupdf):\n",
    "    groupdf['target'] = np.append(\n",
    "        permutation(2), binomial(n=1, p=0.8, size=len(groupdf) - 2))\n",
    "    return groupdf\n",
    "\n",
    "\n",
    "# Data Split\n",
    "df = df.groupby(\"AEDECOD\").apply(sampling)\n",
    "\n",
    "print('All Record')\n",
    "count_aeterm(df_all)\n",
    "print('#AEDECOD>=2')\n",
    "count_aeterm(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df.query('target==0')\n",
    "df_train = df.query('target==1')\n",
    "# Shuffle\n",
    "texts = texts2list(df_train['AETERM'])\n",
    "decods = df_train['AEDECOD']\n",
    "\n",
    "# All shuffled words\n",
    "# shuffled = []\n",
    "# shuffled = [ list(perm) + [decod,] for text, decod in zip(texts, decods) for perm in list(permutations(text,r=MAX_WORDS))]\n",
    "\n",
    "# Random sampling from shuffled words\n",
    "MAX_SEQ = 5\n",
    "shuffled = []\n",
    "for text, decod in zip(texts, decods):\n",
    "    #Number of permuations\n",
    "    pr = scipy.special.perm(len(text), min(MAX_WORDS, len(text)), exact=True)\n",
    "    #Sampling from shuffled words\n",
    "    perms = random.sample(\n",
    "        list(permutations(text, r=min(MAX_WORDS, len(text)))), min(pr, MAX_SEQ))\n",
    "    for perm in perms:\n",
    "        shuffled.append(list(perm) + [decod,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = [coder[pt[-1]] for pt in shuffled]\n",
    "y_train = to_categorical(y_train)\n",
    "x_train = [record[0:-1] for record in shuffled]\n",
    "x_train, nonnull = texts2wv(x_train)\n",
    "\n",
    "y_test = [coder[pt] for pt in df_test['AEDECOD']]\n",
    "y_test = to_categorical(y_test)\n",
    "x_test = texts2list(df_test['AETERM'])\n",
    "x_test, nonnull = texts2wv(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of y_train= 1524\n",
      "x_train_rnn.shape=, y_train.shape= (11124, 5, 400) (11124, 1524)\n",
      "x_test_rnn.shape= (11124, 5, 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yo/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1524, kernel_initializer=<function ...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 200)               400800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1524)              306324    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1524)              0         \n",
      "=================================================================\n",
      "Total params: 707,124\n",
      "Trainable params: 707,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf858926d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.9668670182\n",
      "test acc: 0.590694006497\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "n_hidden = 100\n",
    "n_out = len(y_train[0])\n",
    "\n",
    "x_train_rnn = x_train.reshape(len(x_train), MAX_WORDS, wvsize)\n",
    "x_test_rnn = x_test.reshape(len(x_test), MAX_WORDS, wvsize)\n",
    "\n",
    "print(\"length of y_train=\", n_out)\n",
    "print(\"x_train_rnn.shape=, y_train.shape=\", x_train_rnn.shape, y_train.shape)\n",
    "print(\"x_test_rnn.shape=\", x_train_rnn.shape)\n",
    "\n",
    "\n",
    "def weight_variable(shape, name=None):\n",
    "    return np.random.normal(scale=.01, size=shape)\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(SimpleRNN(n_hidden),\n",
    "#                         input_shape=(MAX_WORDS, wvsize)))\n",
    "# model.add(Dense(n_out, init=weight_variable))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(n_hidden), input_shape=(MAX_WORDS, wvsize)))\n",
    "model.add(Dense(n_out, init=weight_variable))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=SGD(lr=0.1),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "hist = model.fit(\n",
    "    x_train_rnn,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=0,\n",
    "    validation_split=0.2)\n",
    "\n",
    "# plot results\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "epochs = len(acc)\n",
    "plt.plot(range(epochs), acc, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_acc, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test_rnn, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test acc:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 400)               800400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1524)              611124    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1524)              0         \n",
      "=================================================================\n",
      "Total params: 1,892,724\n",
      "Trainable params: 1,892,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10011 samples, validate on 1113 samples\n",
      "Epoch 1/50\n",
      "10011/10011 [==============================] - 0s - loss: 5.5811 - acc: 0.0532 - val_loss: 5.7400 - val_acc: 0.0288\n",
      "Epoch 2/50\n",
      "10011/10011 [==============================] - 0s - loss: 4.4868 - acc: 0.1382 - val_loss: 5.1428 - val_acc: 0.1527\n",
      "Epoch 3/50\n",
      "10011/10011 [==============================] - 0s - loss: 3.7391 - acc: 0.2381 - val_loss: 4.8093 - val_acc: 0.2525\n",
      "Epoch 4/50\n",
      "10011/10011 [==============================] - 0s - loss: 3.1290 - acc: 0.3273 - val_loss: 4.4719 - val_acc: 0.3145\n",
      "Epoch 5/50\n",
      "10011/10011 [==============================] - 0s - loss: 2.6799 - acc: 0.3952 - val_loss: 4.1878 - val_acc: 0.3702\n",
      "Epoch 6/50\n",
      "10011/10011 [==============================] - 0s - loss: 2.3787 - acc: 0.4305 - val_loss: 4.1123 - val_acc: 0.3729\n",
      "Epoch 7/50\n",
      "10011/10011 [==============================] - 0s - loss: 2.1134 - acc: 0.4743 - val_loss: 4.0722 - val_acc: 0.4079\n",
      "Epoch 8/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.8789 - acc: 0.5192 - val_loss: 3.9583 - val_acc: 0.4340\n",
      "Epoch 9/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.7347 - acc: 0.5421 - val_loss: 3.8994 - val_acc: 0.4178\n",
      "Epoch 10/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.5694 - acc: 0.5790 - val_loss: 3.8984 - val_acc: 0.4286\n",
      "Epoch 11/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.4394 - acc: 0.5982 - val_loss: 3.9453 - val_acc: 0.4555\n",
      "Epoch 12/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.3368 - acc: 0.6243 - val_loss: 3.9082 - val_acc: 0.4672\n",
      "Epoch 13/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.2592 - acc: 0.6418 - val_loss: 3.9328 - val_acc: 0.4717\n",
      "Epoch 14/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.1552 - acc: 0.6690 - val_loss: 3.9116 - val_acc: 0.4735\n",
      "Epoch 15/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.0873 - acc: 0.6818 - val_loss: 3.8709 - val_acc: 0.4672\n",
      "Epoch 16/50\n",
      "10011/10011 [==============================] - 0s - loss: 1.0462 - acc: 0.7003 - val_loss: 4.0331 - val_acc: 0.4780\n",
      "Epoch 17/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.9868 - acc: 0.7080 - val_loss: 4.0323 - val_acc: 0.4672\n",
      "Epoch 18/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.9531 - acc: 0.7198 - val_loss: 4.0156 - val_acc: 0.4924\n",
      "Epoch 19/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.8911 - acc: 0.7364 - val_loss: 3.9259 - val_acc: 0.4951\n",
      "Epoch 20/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.8452 - acc: 0.7455 - val_loss: 4.1380 - val_acc: 0.4735\n",
      "Epoch 21/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.8108 - acc: 0.7533 - val_loss: 4.1880 - val_acc: 0.4879\n",
      "Epoch 22/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.7930 - acc: 0.7612 - val_loss: 4.1092 - val_acc: 0.4816\n",
      "Epoch 23/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.7804 - acc: 0.7603 - val_loss: 4.0379 - val_acc: 0.4978\n",
      "Epoch 24/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.7318 - acc: 0.7829 - val_loss: 4.1838 - val_acc: 0.5121\n",
      "Epoch 25/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.7041 - acc: 0.7876 - val_loss: 4.1173 - val_acc: 0.4906\n",
      "Epoch 26/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.6712 - acc: 0.7957 - val_loss: 4.2143 - val_acc: 0.4924\n",
      "Epoch 27/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.6686 - acc: 0.7988 - val_loss: 4.2199 - val_acc: 0.4870\n",
      "Epoch 28/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.6427 - acc: 0.8030 - val_loss: 4.2059 - val_acc: 0.4897\n",
      "Epoch 29/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.6520 - acc: 0.8013 - val_loss: 4.1958 - val_acc: 0.5049\n",
      "Epoch 30/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.6203 - acc: 0.8109 - val_loss: 4.2052 - val_acc: 0.4843\n",
      "Epoch 31/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.6091 - acc: 0.8146 - val_loss: 4.2490 - val_acc: 0.4915\n",
      "Epoch 32/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5944 - acc: 0.8168 - val_loss: 4.2399 - val_acc: 0.4798\n",
      "Epoch 33/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5725 - acc: 0.8243 - val_loss: 4.3781 - val_acc: 0.4960\n",
      "Epoch 34/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5591 - acc: 0.8292 - val_loss: 4.2181 - val_acc: 0.5121\n",
      "Epoch 35/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5562 - acc: 0.8287 - val_loss: 4.2383 - val_acc: 0.4996\n",
      "Epoch 36/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5297 - acc: 0.8345 - val_loss: 4.2819 - val_acc: 0.5013\n",
      "Epoch 37/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5363 - acc: 0.8334 - val_loss: 4.2971 - val_acc: 0.5058\n",
      "Epoch 38/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5086 - acc: 0.8409 - val_loss: 4.1587 - val_acc: 0.5184\n",
      "Epoch 39/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5099 - acc: 0.8404 - val_loss: 4.2545 - val_acc: 0.4942\n",
      "Epoch 40/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5217 - acc: 0.8403 - val_loss: 4.2342 - val_acc: 0.5067\n",
      "Epoch 41/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4946 - acc: 0.8508 - val_loss: 4.2660 - val_acc: 0.5229\n",
      "Epoch 42/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4808 - acc: 0.8529 - val_loss: 4.3014 - val_acc: 0.5175\n",
      "Epoch 43/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.5038 - acc: 0.8431 - val_loss: 4.1619 - val_acc: 0.5229\n",
      "Epoch 44/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4797 - acc: 0.8549 - val_loss: 4.3268 - val_acc: 0.5184\n",
      "Epoch 45/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4578 - acc: 0.8550 - val_loss: 4.3140 - val_acc: 0.5139\n",
      "Epoch 46/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4744 - acc: 0.8551 - val_loss: 4.3111 - val_acc: 0.5337\n",
      "Epoch 47/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4475 - acc: 0.8600 - val_loss: 4.4711 - val_acc: 0.5148\n",
      "Epoch 48/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4602 - acc: 0.8612 - val_loss: 4.3728 - val_acc: 0.5193\n",
      "Epoch 49/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4558 - acc: 0.8620 - val_loss: 4.3377 - val_acc: 0.5247\n",
      "Epoch 50/50\n",
      "10011/10011 [==============================] - 0s - loss: 0.4365 - acc: 0.8667 - val_loss: 4.4077 - val_acc: 0.5130\n",
      "test loss: 3.61070847887\n",
      "test acc: 0.517350157917\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nglJKKR9NCkoppXw0KSillPL5/yUAI3I+/LoBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf837d46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_in = len(x_train[0])\n",
    "n_hidden = 400\n",
    "n_out = len(y_train[0])\n",
    "dropout_rate = 0.4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim=n_in))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=SGD(lr=1),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_split=0.1)\n",
    "\n",
    "#,                  callbacks=[es, csv_logger]\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test acc:', score[1])\n",
    "\n",
    "# plot results\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "epochs = len(acc)\n",
    "plt.plot(range(epochs), acc, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_acc, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not shuffle words\n",
    "\n",
    "texts = texts2list(df['AETERM'])\n",
    "x_all, nonull = texts2wv(texts)\n",
    "y_all = np.asarray(\n",
    "    [coder[df['AEDECOD'][i]] for i in range(0, len(df['AEDECOD']))])\n",
    "y_all = to_categorical(y_all)\n",
    "target = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "n_hidden = 200\n",
    "n_out = len(y_all[0])\n",
    "\n",
    "\n",
    "def split_data(x, y, target):\n",
    "    x_train = x[target == 1]\n",
    "    x_test = x[target == 0]\n",
    "    y_train = y[target == 1]\n",
    "    y_test = y[target == 0]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(x_all, y_all, target)\n",
    "\n",
    "x_train = x_train.reshape(len(x_train), MAX_WORDS, wvsize)\n",
    "x_test = x_test.reshape(len(x_test), MAX_WORDS, wvsize)\n",
    "\n",
    "print(\"length of y_all=\", n_out)\n",
    "print(\"x_all.shape=, y_all.shape=\", x_all.shape, y_all.shape)\n",
    "print(\"x_train.shape=\", x_train.shape)\n",
    "\n",
    "\n",
    "def weight_variable(shape, name=None):\n",
    "    return np.random.normal(scale=.01, size=shape)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(n_hidden), input_shape=(MAX_WORDS, wvsize)))\n",
    "model.add(Dense(n_out, init=weight_variable))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(LSTM(n_hidden),\n",
    "#                         input_shape=(MAX_WORDS, wvsize)))\n",
    "# model.add(Dense(n_out, init=weight_variable))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', optimizer=SGD(lr=1), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=0,\n",
    "    validation_split=0.1)\n",
    "\n",
    "# plot results\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "epochs = len(acc)\n",
    "plt.plot(range(epochs), acc, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_acc, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test acc:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in = len(x_all[0])\n",
    "n_hidden = 400\n",
    "n_out = len(y_all[0])\n",
    "print(n_in, n_out)\n",
    "print(x_all.shape, y_all.shape)\n",
    "\n",
    "\n",
    "def split_data(x, y, target):\n",
    "    x_train = x[target == 1]\n",
    "    x_test = x[target == 0]\n",
    "    y_train = y[target == 1]\n",
    "    y_test = y[target == 0]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(x_all, y_all, target)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim=n_in))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=SGD(lr=1),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=0,\n",
    "    validation_split=0.1)\n",
    "\n",
    "#,                  callbacks=[es, csv_logger]\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test acc:', score[1])\n",
    "\n",
    "# plot results\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "epochs = len(acc)\n",
    "plt.plot(range(epochs), acc, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_acc, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "\n",
    "y_test_decode = [decoder[i] for i in np.where(y_test == 1)[1]]\n",
    "y_predict_decode = [decoder[i] for i in y_predict.argmax(axis=1)]\n",
    "y_decode = pd.DataFrame(\n",
    "    np.array([y_test_decode, y_predict_decode]).T, columns=['test', 'predict'])\n",
    "\n",
    "#print(y_decode[0:10])\n",
    "dfx = df[df[\"target\"] == 0].reset_index(drop=True, inplace=False)\n",
    "result = pd.concat([dfx, y_decode], axis=1)\n",
    "result['judge'] = result['AEDECOD'] == result['predict']\n",
    "result['check'] = result['AEDECOD'] == result['test']\n",
    "#result['check'].sum()\n",
    "accuracy = 100 * result['judge'].sum() / len(result)\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "summary = result.groupby('len').sum()\n",
    "summary['Acurracy'] = 100 * summary['judge'] / summary['check']\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear', random_state=None)\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#model = LogisticRegression(random_state=None)\n",
    "y_train_cat = np.where(y_train == 1)[1]\n",
    "y_test_cat = np.where(y_test == 1)[1]\n",
    "model.fit(x_train, y_train_cat)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred_train = model.predict(x_train)\n",
    "accuracy_train = accuracy_score(y_train_cat, pred_train)\n",
    "print('SVM training accuracy: %.2f' % accuracy_train)\n",
    "\n",
    "pred_test = model.predict(x_test)\n",
    "accuracy_test = accuracy_score(y_test_cat, pred_test)\n",
    "print('SVMtest accuracy: %.2f' % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "forest = RandomForestClassifier(min_samples_leaf=3, random_state=0)\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "pred_train = model.predict(x_train)\n",
    "accuracy_train = accuracy_score(y_train_cat, pred_train)\n",
    "print('RF training accuracy: %.2f' % accuracy_train)\n",
    "\n",
    "pred_test = model.predict(x_test)\n",
    "accuracy_test = accuracy_score(y_test_cat, pred_test)\n",
    "print('RF test accuracy: %.2f' % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_decode = [decoder[i] for i in np.where(y_train == 1)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('./data/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intexts = texts2list([\"Vomit a food\", \"low back pain\"])\n",
    "x_in, nonull = texts2wv(intexts)\n",
    "y_predict = model.predict(x_in)\n",
    "decoder = dict([(pt, index) for index, pt in coder.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = y_predict.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder[index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "wikimodel = Word2Vec.load(\"./data/wiki.en.word2vec.model100\")\n",
    "#wikimodel = KeyedVectors.load_word2vec_format(\"./data/test.model\",binary=False)\n",
    "#with open('/home/yo/PycharmProjects/coding/data/test.model','rb') as f:\n",
    "#    wikimodel = pickle.load(f)\n",
    "\n",
    "wvsize = wikimodel.vector_size\n",
    "MAX_WORDS = 5\n",
    "\n",
    "\n",
    "def is_ascii(string):\n",
    "    \"\"\"return true if non ascii characters are detected in the given string\n",
    "    \"\"\"\n",
    "    if string:\n",
    "        return max([ord(char) for char in string]) < 128\n",
    "    return True\n",
    "\n",
    "\n",
    "def texts2list(texts):\n",
    "    stop_words = set('for a of the and to in by with'.split())\n",
    "    if type(texts) == list:\n",
    "        texts = pd.Series(texts)\n",
    "    texts = texts.str.lower().str.translate(str.maketrans('()', '  '))\n",
    "    texts = texts.str.strip()\n",
    "    textlist = [[\n",
    "        word for word in document.translate(\n",
    "            str.maketrans('\\'()[],.&?\"{}-_:;', '                ')).split()\n",
    "        if word not in stop_words\n",
    "    ] for document in texts]\n",
    "    return textlist\n",
    "\n",
    "\n",
    "def texts2wv(texts):\n",
    "    dictset = list(set(chain.from_iterable(texts)))\n",
    "    wvdict = dict([(dic, wikimodel[dic]) for dic in dictset\n",
    "                   if dic in wikimodel.wv.vocab])\n",
    "    wvsize = wikimodel.vector_size\n",
    "    wv = [\n",
    "        np.array([wvdict[word] for word in text if word in wvdict.keys()])\n",
    "        for text in texts\n",
    "    ]\n",
    "    nonull = [len(vector) for vector in wv]\n",
    "    x = [\n",
    "        np.array([\n",
    "            wvdict[word] for (i, word) in enumerate(text)\n",
    "            if word in wvdict.keys()\n",
    "        ]) for text in texts\n",
    "    ]\n",
    "    x_norm = [x[i][0:MAX_WORDS] for i in range(len(x))]\n",
    "    x_all = np.array([\n",
    "        np.append(x_norm[i].flat,\n",
    "                  np.zeros(wvsize * max(MAX_WORDS - len(x_norm[i]), 0)))\n",
    "        for i in range(len(x_norm))\n",
    "    ])\n",
    "    return x_all, nonull\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('./data/model.h5')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "with open(os.path.join('.', 'data', 'coder.pkl'), 'rb') as f:\n",
    "    coder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(intexts)\n",
    "print(x_in)\n",
    "print(nonnull)\n",
    "print(y_predict)\n",
    "print(index)\n",
    "print(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "with open('/home/yo/PycharmProjects/coding/data/wikimodel', 'wb') as f:\n",
    "    pickle.dump(wikimodel, f)\n",
    "f.closed\n",
    "\n",
    "#wikimodel.save('/home/yo/PycharmProjects/coding/data/test.model',sep_limit=100*1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "with open('/home/yo/PycharmProjects/coding/data/test.model', 'rb') as f:\n",
    "    wikimodel = pickle.load(f)\n",
    "\n",
    "#wvsize = wikimodel.vector_size\n",
    "\n",
    "wikimodel.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/yo/PycharmProjects/coding/data/test.model.bin',\n",
    "          'rb') as gcs_file:\n",
    "    test = gcs_file.read()\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
